{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'79f63113-35b5-4c67-9cce-54c95a104938'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(),override=True)\n",
    "\n",
    "os.environ.get('PINECONE_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_document(file):\n",
    "     from langchain.document_loaders import PyPDFLoader\n",
    "     print(f'Loading{file}')\n",
    "     loader= PyPDFLoader(file)\n",
    "     data=loader.load()\n",
    "     return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_data(data, chunk_size=256):\n",
    "    from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "    text_splitter= RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=0)\n",
    "    chunks= text_splitter.split_documents(data)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_embedding_cost(texts):\n",
    "    import tiktoken\n",
    "    enc= tiktoken.encoding_for_model('text-embedding-ada-002')\n",
    "    total_tokens= sum([len(enc.encode(page.page_content)) for page in texts])\n",
    "    print(f'Total Tokens: {total_tokens}')\n",
    "    print(f'Embedding Cost in USD: {total_tokens/1000*.004:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_or_fetch_embeddings(index_name):\n",
    "    import pinecone\n",
    "    from langchain.vectorstores import Pinecone\n",
    "    from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "    \n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    \n",
    "    pinecone.init(api_key=os.environ.get('PINECONE_API_KEY'), environment=os.environ.get('PINECONE_ENV'))\n",
    "    \n",
    "    if index_name in pinecone.list_indexes():\n",
    "        print(f'Index {index_name} already exists. Loading embeddings ... ', end='')\n",
    "        vector_store = Pinecone.from_existing_index(index_name, embeddings)\n",
    "        print('Ok')\n",
    "    else:\n",
    "        print(f'Creating index {index_name} and embeddings ...', end='')\n",
    "        pinecone.create_index(index_name, dimension=1536, metric='cosine')\n",
    "        vector_store = Pinecone.from_documents(chunks, embeddings, index_name=index_name)\n",
    "        print('Ok')\n",
    "        \n",
    "    return vector_store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_pinecone_index(index_name='all'):\n",
    "    import pinecone\n",
    "    pinecone.init(api_key=os.environ.get('PINECONE_API_KEY'), environment=os.environ.get('PINECONE_ENV'))\n",
    "    \n",
    "    if index_name == 'all':\n",
    "        indexes = pinecone.list_indexes()\n",
    "        print('Deleting all indexes ... ')\n",
    "        for index in indexes:\n",
    "            pinecone.delete_index(index)\n",
    "        print('Ok')\n",
    "    else:\n",
    "        print(f'Deleting index {index_name} ...', end='')\n",
    "        pinecone.delete_index(index_name)\n",
    "        print('Ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_and_get_answer(vector_store, q):\n",
    "    from langchain.chains import RetrievalQA\n",
    "    from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "    llm = ChatOpenAI(model='gpt-3.5-turbo', temperature=1)\n",
    "\n",
    "    retriever = vector_store.as_retriever(search_type='similarity', search_kwargs={'k': 3})\n",
    "\n",
    "    chain = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever)\n",
    "    \n",
    "    answer = chain.run(q)\n",
    "    return answer\n",
    "    \n",
    "    \n",
    "def ask_with_memory(vector_store, question, chat_history=[]):\n",
    "    from langchain.chains import ConversationalRetrievalChain\n",
    "    from langchain.chat_models import ChatOpenAI\n",
    "    \n",
    "    llm = ChatOpenAI(temperature=1)\n",
    "    retriever = vector_store.as_retriever(search_type='similarity', search_kwargs={'k': 3})\n",
    "    \n",
    "    crc = ConversationalRetrievalChain.from_llm(llm, retriever)\n",
    "    result = crc({'question': question, 'chat_history': chat_history})\n",
    "    chat_history.append((question, result['answer']))\n",
    "    \n",
    "    return result, chat_history\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoadingF:\\01. AI\\NLP\\LLM\\2023 End-to-End Handwritten Paragraph Text Recognition.pdf\n",
      "also highlight that the reading order is deﬁned by hand, based\n",
      "on the coordinates of the text regions; this could lead to some\n",
      "errors in the case of rather slanted lines.\n",
      "This paper aims at providing a model freed from all of\n",
      "these constraints. We suggest using a segmentation-free\n",
      "model that processes whole handwritten paragraphs using\n",
      "an attention process. The use of a line-segmentation-free\n",
      "approach has already been proposed for other tasks such as\n",
      "probabilistic keyword spotting and indexing for example\n",
      "[2]. However, in [2], the segmentation is superseded by a\n",
      "ﬁxed sliding window process over the vertical axis. On the\n",
      "contrary, in the model we propose, character recognition\n",
      "and implicit line segmentation are learned in an end-to-end\n",
      "fashion, so as to optimize both processes altogether.\n",
      "Most of the contributions of the literature have success-\n",
      "fully used neural networks for line segmentation and text\n",
      "line recognition as well, reaching state-of-the-art results. In\n",
      "addition, Attention Neural Networks have been success-\n",
      "fully applied for many other tasks such as translation [3],\n",
      "speech recognition [4], image captioning [5] or even OCR\n",
      "applied at line level [6]. This leads us to think that both tasks\n",
      "(segmentation and recognition) could be handled by a sin-\n",
      "gle neural network with attention as a control block.\n",
      "In this paper, we propose an encoder-decoder architecture\n",
      "using a hybrid (content-based and location-based) attention\n",
      "mechanism to process whole paragraph images. The idea is to\n",
      "recurrently recognize the lines so as to remain in a one-dimen-\n",
      "sional sequence alignment problem between the recognized\n",
      "text lines and their ground truth transcription. This alignment\n",
      "is achieved during training using the standard Connectionist\n",
      "Temporal Classiﬁcation (CTC) loss [7]. To this end, we ﬁrst\n",
      "use an encoder to extract two-dimensional features from the\n",
      "input paragraph images. These features account for the char-\n",
      "acters while preserving their location. The text line location\n",
      "and their reading order are both handled and learned by the\n",
      "attention module. This attention mechanism aims at focusing\n",
      "on speciﬁc feature rows to generate text line representations.\n",
      "They are generated recurrently, one at a time, from the ﬁrst\n",
      "one to the last one, through the attention mechanism. The\n",
      "decoder recognizes a sequence of characters from each text\n",
      "line representation. A whitespace character is inserted\n",
      "between each recognized text line to get the ﬁnal paragraph.\n",
      "In brief, we make the following contributions:\n",
      "/C15We propose the Vertical Attention Network: a novel\n",
      "encoder-decoder architecture using hybrid attention\n",
      "for text recognition at paragraph level.\n",
      "/C15The approach relies on an implicit line segmentation\n",
      "performed in the latent space of a deep model.\n",
      "/C15We achieve state-of-the-art results on RIMES, IAM\n",
      "and READ 2016 datasets compared to paragraph-\n",
      "level approaches.\n",
      "/C15We compare favorably this architecture with a stan-\n",
      "dard two-step approach based on line segmentation\n",
      "followed by character recognition.\n",
      "This paper is organized as follows. Related works are pre-\n",
      "sented in Section 2. Section 3 is dedicated to the presentation\n",
      "of the proposed architecture. Section 4 is devoted to the\n",
      "experimental environment. It provides, inter alia , description\n",
      "of datasets, training and implementation details. Experi-\n",
      "ments and results are detailed in Section 5. We carried outextensive experiments in Section 6. Section 7 provides a dis-\n",
      "cussion of the model and we draw conclusions in Section 8.\n",
      "2R ELATED WORKS\n",
      "In the literature, only very few works have been devoted to\n",
      "multi-line text recognition, and most studies have concen-\n",
      "trated on isolated lines recognition. We can classify these pio-\n",
      "neer works into two categories: those using an explicit word/\n",
      "line segmentation, requiring segmentation and transcription\n",
      "labels, and those without any segmentation, only requiring\n",
      "transcription labels.\n",
      "2.1 Approaches Using Explicit Line Segmentation\n",
      "Explicit line segmentation approaches are two-step methods\n",
      "that sequentially detect the text lines of a paragraph, and\n",
      "then proceed to their recognition. To our knowledge, [8] is\n",
      "the only reference that gathers in the same study segmenta-\n",
      "tion and text line recognition as two separate networks.\n",
      "However, a lot of works focus on one of these two tasks\n",
      "separately.\n",
      "Early segmentation techniques [9] can be classiﬁed in\n",
      "three categories as suggested in [10]. First, the projection-\n",
      "based methods, which consider the boundaries between\n",
      "lines as valleys of vertical projection proﬁle [11]. Second, the\n",
      "grouping methods; it consists in grouping rows of con-\n",
      "nected components according to heuristic rules [12]. The\n",
      "last category is the smearing methods which use blurring\n",
      "ﬁlters combined with binarization or active contours for\n",
      "example [13]. It is now generally handled by a Fully Convo-\n",
      "lutional Network (FCN) as in [1], [14], [15].\n",
      "Regarding handwritten lines recognition, it was ﬁrst\n",
      "solved using handcrafted features and Hidden Markov\n",
      "Model (HMM) [16], [17]. However, those models lacked dis-\n",
      "criminative power and were limited when dealing with long\n",
      "term dependencies in sequences. Hybrid systems combining\n",
      "HMM with Neural Networks (NN) were proposed, leading\n",
      "to better results over standard HMM: HMM with MultiLayer\n",
      "Perceptron (HMM+MLP) [18], [19], [20], [21], HMM with\n",
      "Convolutional Neural Network (HMM+CNN) [22] or HMM\n",
      "with Recurrent Neural Network (HMM+RNN) [23], [24]. Cur-\n",
      "rently, the state of the art is reached with neural networks.\n",
      "Many kinds of architectures have been proposed: Multi-\n",
      "Dimensional Long-Short Term Memory (MDLSTM) [25],\n",
      "hybrid CNN and Bidirectional LSTM (BLSTM) [26], [27] and\n",
      "more recently encoder-decoder with attention [28], Gated\n",
      "CCN (GCNN) [29] and Gated FCN (GFCN) [30], [31]. Except\n",
      "for attention-based character recognition models, which use\n",
      "cross-entropy loss, training an OCR model at line level was\n",
      "made possible thanks to the CTC. Indeed, it enables to align\n",
      "output sequences of characters with input sequences of fea-\n",
      "tures (or pixels) of different and variable lengths.\n",
      "Recently, one can notice a trend toward gathering seg-\n",
      "mentation and recognition together. For the segmentation\n",
      "stage, we can distinguish two approaches: the ﬁrst one\n",
      "comes from object detection methods and the second one is\n",
      "based on start-of-line prediction.\n",
      "The models proposed in [8], [32], [33] follow the object\n",
      "detection approach: they are based on word (or line) bound-\n",
      "ing boxes prediction. They use a Region Proposal Network\n",
      "(RPN) combined with a non-maximal suppression processCOQUENET ET AL.: END-TO-END HANDWRITTEN PARAGRAPH TEXT RECOGNITION USING A VERTICAL ATTENTION NETWORK 509\n",
      "Authorized licensed use limited to: Rajshahi University Of Engineering and Technology. Downloaded on November 11,2023 at 10:00:31 UTC from IEEE Xplore.  Restrictions apply. \n"
     ]
    }
   ],
   "source": [
    "data= load_document(r'F:\\01. AI\\NLP\\LLM\\2023 End-to-End Handwritten Paragraph Text Recognition.pdf')\n",
    "print(data[1].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    }
   ],
   "source": [
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "422\n",
      "page_content='over, they have rarely been studied and optimized together\\nin one single trainable system.\\nHistorically, early works have applied segmentation at\\ncharacter level and each character was then classiﬁed. Later' metadata={'source': 'F:\\\\01. AI\\\\NLP\\\\LLM\\\\2023 End-to-End Handwritten Paragraph Text Recognition.pdf', 'page': 0}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "chunks= chunk_data(data)\n",
    "print(len(chunks))\n",
    "print(chunks[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tokens: 24379\n",
      "Embedding Cost in USD: 0.097516\n"
     ]
    }
   ],
   "source": [
    "print_embedding_cost(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\01. AI\\NLP\\LLM\\venv\\Lib\\site-packages\\pinecone\\index.py:4: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting all indexes ... \n",
      "Ok\n"
     ]
    }
   ],
   "source": [
    "delete_pinecone_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating index brailledoc and embeddings ...Ok\n"
     ]
    }
   ],
   "source": [
    "index_name= 'brailledoc'\n",
    "vector_store= insert_or_fetch_embeddings(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The PDF discusses the process of recognizing text in scanned images and highlights the challenge of determining the reading order for slanted lines. The paper aims to provide a model that eliminates such errors. For more information, the reader is directed to the Digital Library at www.computer.org/csdl.\n"
     ]
    }
   ],
   "source": [
    "q = 'summarize the pdf'\n",
    "answer = ask_and_get_answer(vector_store, q)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
